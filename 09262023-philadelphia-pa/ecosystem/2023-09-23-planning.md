# Ecosystem

Planning session notes from Tuesday morning.
We also did some work around the **pointcloud** extension.

## STAC items to data

How do you consume the data that STAC points to?

1. Item -> data story
    * How do I get from my found STAC items to the data themselves?
    * Exploitation / analysis
    * Which data products should folks be using? Do they even know what they should be using?
2. STAC -> OpenDataCube interop
    * lat/lon
    * time
    * data array per band
    * find out if it's cf-conventions
    * Not too different (and maybe the same) as the current L2->L3 problem
3. `kerchunk` extension
    * Maybe a "reference file extension"
4. TileDB v Zarr?
    * TileDB is a company, might be better at sparse (but might not, TileDB is _ok_ at sparse but not as fleshed out as the dense)
    * STAC doesn't have opinions on formats
        * STAC should get you to **xarray** (for rasters)
            * Except if its table data
            * This is for tooling not the spec

## General topics

1. Taking a look at the STAC reader in PDAL
2. Create a STAC writer for PDAL
3. PySTAC 1.1 prep
4. PySTAC extensions design discussion
    * What's the need?
    * What's the gaps with the current solution?
5. What is the point of **stactools**?
    * In-breakout session discussion
        * Useful on the command line to Do Workâ„¢
        * It's too heavy for some use-cases
    * Make the story make more sense
    * Make "create STAC from an asset" easier for the community
    * **stactools-packages** and **stactools** are for _creating_ STAC metadata, not consuming
    * **stac-builder**?
6. Tutorials, aka "I get it!" story around why STAC is a good thing to include in your stack
    * Consolidate tutorials
7. Authentication ("secure assets") extension: <https://github.com/AtomicMaps/authentication>

## Done

1. Audit STAC point cloud extension
    * <https://github.com/stac-extensions/pointcloud/issues/9>
    * <https://github.com/stac-extensions/pointcloud/issues/8>
